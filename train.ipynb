{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\scoop\\apps\\python\\current\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from utils import save_checkpoint, load_checkpoint, save_some_examples\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import config\n",
    "from dataset import MapDataset\n",
    "from generator_model import Generator\n",
    "from discriminator_model import Discriminator\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(\n",
    "    disc, gen, loader, opt_disc, opt_gen, l1_loss, bce, g_scaler, d_scaler,\n",
    "):\n",
    "    loop = tqdm(loader, leave=True)\n",
    "\n",
    "    for idx, (x, y) in enumerate(loop):\n",
    "        x = x.to(config.DEVICE)\n",
    "        y = y.to(config.DEVICE)\n",
    "\n",
    "        # Train Discriminator\n",
    "        with torch.cuda.amp.autocast():\n",
    "            y_fake = gen(x)\n",
    "            D_real = disc(x, y)\n",
    "            D_real_loss = bce(D_real, torch.ones_like(D_real))\n",
    "            D_fake = disc(x, y_fake.detach())\n",
    "            D_fake_loss = bce(D_fake, torch.zeros_like(D_fake))\n",
    "            D_loss = (D_real_loss + D_fake_loss) / 2\n",
    "\n",
    "        disc.zero_grad()\n",
    "        d_scaler.scale(D_loss).backward()\n",
    "        d_scaler.step(opt_disc)\n",
    "        d_scaler.update()\n",
    "\n",
    "        # Train generator\n",
    "        with torch.cuda.amp.autocast():\n",
    "            D_fake = disc(x, y_fake)\n",
    "            G_fake_loss = bce(D_fake, torch.ones_like(D_fake))\n",
    "            L1 = l1_loss(y_fake, y) * config.L1_LAMBDA\n",
    "            G_loss = G_fake_loss + L1\n",
    "\n",
    "        opt_gen.zero_grad()\n",
    "        g_scaler.scale(G_loss).backward()\n",
    "        g_scaler.step(opt_gen)\n",
    "        g_scaler.update()\n",
    "\n",
    "        if idx % 10 == 0:\n",
    "            loop.set_postfix(\n",
    "                D_real=torch.sigmoid(D_real).mean().item(),\n",
    "                D_fake=torch.sigmoid(D_fake).mean().item(),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    disc = Discriminator(in_channels=3).to(config.DEVICE)\n",
    "    gen = Generator(in_channels=3, features=64).to(config.DEVICE)\n",
    "    opt_disc = optim.Adam(disc.parameters(), lr=config.LEARNING_RATE, betas=(0.5, 0.999),)\n",
    "    opt_gen = optim.Adam(gen.parameters(), lr=config.LEARNING_RATE, betas=(0.5, 0.999))\n",
    "    BCE = nn.BCEWithLogitsLoss()\n",
    "    L1_LOSS = nn.L1Loss()\n",
    "\n",
    "    if config.LOAD_MODEL:\n",
    "        load_checkpoint(\n",
    "            config.CHECKPOINT_GEN, gen, opt_gen, config.LEARNING_RATE,\n",
    "        )\n",
    "        load_checkpoint(\n",
    "            config.CHECKPOINT_DISC, disc, opt_disc, config.LEARNING_RATE,\n",
    "        )\n",
    "\n",
    "    train_dataset = MapDataset()\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=config.NUM_WORKERS,\n",
    "    )\n",
    "    g_scaler = torch.cuda.amp.GradScaler()\n",
    "    d_scaler = torch.cuda.amp.GradScaler()\n",
    "    val_dataset = MapDataset(root_dir_input = \"D:/2A/Projet_PFA/AdnGAN/Drive_data/seg_val/seg/\",root_dir_target = \"D:/2A/Projet_PFA/AdnGAN/Drive_data/rgb_val/images/\")\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    for epoch in range(config.NUM_EPOCHS):\n",
    "        train_fn(\n",
    "            disc, gen, train_loader, opt_disc, opt_gen, L1_LOSS, BCE, g_scaler, d_scaler,\n",
    "        )\n",
    "\n",
    "        if config.SAVE_MODEL and epoch % 5 == 0:\n",
    "            save_checkpoint(gen, opt_gen, filename=config.CHECKPOINT_GEN)\n",
    "            save_checkpoint(disc, opt_disc, filename=config.CHECKPOINT_DISC)\n",
    "\n",
    "        save_some_examples(gen, val_loader, epoch, folder=\"evaluation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [04:21<00:00,  8.16s/it, D_fake=0.408, D_real=0.579]\n",
      "100%|██████████| 32/32 [03:35<00:00,  6.73s/it, D_fake=0.374, D_real=0.453]\n",
      "100%|██████████| 32/32 [03:17<00:00,  6.17s/it, D_fake=0.45, D_real=0.512] \n",
      "100%|██████████| 32/32 [03:09<00:00,  5.93s/it, D_fake=0.442, D_real=0.542]\n",
      "100%|██████████| 32/32 [02:45<00:00,  5.17s/it, D_fake=0.499, D_real=0.574]\n",
      "100%|██████████| 32/32 [02:40<00:00,  5.01s/it, D_fake=0.466, D_real=0.502]\n",
      "100%|██████████| 32/32 [02:44<00:00,  5.16s/it, D_fake=0.455, D_real=0.548]\n",
      "100%|██████████| 32/32 [03:16<00:00,  6.14s/it, D_fake=0.471, D_real=0.533]\n",
      "100%|██████████| 32/32 [03:27<00:00,  6.48s/it, D_fake=0.453, D_real=0.524]\n",
      "100%|██████████| 32/32 [03:10<00:00,  5.94s/it, D_fake=0.442, D_real=0.511]\n",
      "100%|██████████| 32/32 [02:35<00:00,  4.87s/it, D_fake=0.399, D_real=0.547]\n",
      "100%|██████████| 32/32 [02:47<00:00,  5.23s/it, D_fake=0.481, D_real=0.547]\n",
      "100%|██████████| 32/32 [03:16<00:00,  6.14s/it, D_fake=0.4, D_real=0.58]   \n",
      "100%|██████████| 32/32 [03:25<00:00,  6.42s/it, D_fake=0.407, D_real=0.569]\n",
      "100%|██████████| 32/32 [02:49<00:00,  5.31s/it, D_fake=0.433, D_real=0.542]\n",
      "100%|██████████| 32/32 [02:56<00:00,  5.51s/it, D_fake=0.427, D_real=0.521]\n",
      "100%|██████████| 32/32 [02:55<00:00,  5.48s/it, D_fake=0.427, D_real=0.579]\n",
      "100%|██████████| 32/32 [02:59<00:00,  5.62s/it, D_fake=0.488, D_real=0.543]\n",
      "100%|██████████| 32/32 [02:42<00:00,  5.06s/it, D_fake=0.448, D_real=0.557]\n",
      "100%|██████████| 32/32 [02:47<00:00,  5.25s/it, D_fake=0.478, D_real=0.511]\n",
      "100%|██████████| 32/32 [02:52<00:00,  5.38s/it, D_fake=0.39, D_real=0.582] \n",
      "100%|██████████| 32/32 [03:19<00:00,  6.22s/it, D_fake=0.467, D_real=0.516]\n",
      "100%|██████████| 32/32 [02:38<00:00,  4.97s/it, D_fake=0.494, D_real=0.472]\n",
      "100%|██████████| 32/32 [03:41<00:00,  6.92s/it, D_fake=0.401, D_real=0.563]\n",
      "100%|██████████| 32/32 [03:43<00:00,  6.98s/it, D_fake=0.45, D_real=0.602] \n",
      "100%|██████████| 32/32 [03:26<00:00,  6.45s/it, D_fake=0.431, D_real=0.547]\n",
      "100%|██████████| 32/32 [02:48<00:00,  5.26s/it, D_fake=0.532, D_real=0.489]\n",
      "100%|██████████| 32/32 [03:17<00:00,  6.17s/it, D_fake=0.44, D_real=0.578] \n",
      "100%|██████████| 32/32 [03:11<00:00,  5.97s/it, D_fake=0.354, D_real=0.637]\n",
      "100%|██████████| 32/32 [03:38<00:00,  6.84s/it, D_fake=0.456, D_real=0.525]\n",
      "100%|██████████| 32/32 [04:00<00:00,  7.51s/it, D_fake=0.447, D_real=0.537]\n",
      "100%|██████████| 32/32 [03:17<00:00,  6.16s/it, D_fake=0.306, D_real=0.613]\n",
      "100%|██████████| 32/32 [06:59<00:00, 13.11s/it, D_fake=0.452, D_real=0.497]\n",
      "100%|██████████| 32/32 [07:53<00:00, 14.80s/it, D_fake=0.491, D_real=0.537]\n",
      " 34%|███▍      | 11/32 [02:33<05:02, 14.39s/it, D_fake=0.435, D_real=0.525]"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
